{
  "previous": "Previous",
  "next": "Next",
  "yes": "Yes",
  "no": "No",
  "finish": "Finish",
  "disable": "Disable {{tool}}",
  "enable": "Enable {{tool}}",
  "activate": "Activate {{tool}}",
  "tools": "Tools",
  "webSearch": "Web Search",
  "urlFetcher": "URL Fetcher",
  "agentTools": "Agent Tools",
  "modelAdvanceSettings": "Model Advance Settings",
  "learnMore": "Learn More",
  "close": "Close",
  "closeAndSave": "Close and Save",
  "showActions": "Show Actions",
  "showLess": "Show Less",
  "showMore": "Show More",
  "notSet": "Not Set",
  "voice": "Voice",
  "github": "GitHub",
  "load": "Load",
  "save": "Save",
  "cancel": "Cancel",
  "success": "Success",
  "error": "Error",
  "setDefault": "Set Default",
  "name": "Name",
  "description": "Description",
  "content": "Content",
  "hideFilter": "Hide Filter",
  "showFilter": "Show Filter",
  "searchByName": "Search by name",
  "filterByTags": "Filter by tags",
  "promptName": "Prompt Name",
  "model": "Model",
  "addModel": "Add Model",
  "removeModel": "Remove Model",
  "newModel": "New Model",
  "toolNames": {
    "executeCommand": "Execute Command",
    "readFile": "Read File",
    "writeToFile": "Write To File",
    "searchFiles": "Search Files",
    "listFiles": "List Files",
    "listCodeDefinitionNames": "List Code Definition Names",
    "inspectSite": "Inspect Site",
    "askFollowUpQuestion": "Ask Follow Up Question",
    "attemptCompletion": "Attempt Completion",
    "webSearch": "Web Search",
    "urlFetcher": "URL Fetcher"
  },
  "toolBar": {
    "generalSettings": "General Settings",
    "voiceSettings": "Voice Settings",
    "codeCompletionSettings": "Code Completion Settings",
    "quickGuide": "Quick Start Guide",
    "whatsNew": "What's New",
    "history": "History",
    "newChat": "New Chat",
    "marketplace": "marketplace",
    "editModelList": "Edit Model List"
  },
  "floatButton": {
    "syncDescription": "Synchronize the file changes to chat history"
  },
  "settingsBar": {
    "settingsReloadRequired": "Some settings require a reload to take effect",
    "apiKeySettings": "API Key Settings",
    "hostServerSettings": "Host Server Settings",
    "themeAndCustomize": "Theme and Customize",
    "otherSettings": "Other Settings",
    "themePrimaryColor": "Theme Primary Color",
    "themeAlgorithm": "Theme Algorithm",
    "themeBorderRadius": "Theme Border Radius",
    "lightTheme": "Light",
    "darkTheme": "Dark",
    "compactTheme": "Compact",
    "doubleEnterSendMessagesLabel": "Send messages with double enter",
    "doubleEnterSendMessagesDescription": "Send messages with double enter",
    "keepLoadedContextLabel": "Keep the loaded context",
    "keepLoadedContextDescription": "Costs more RAM but allows faster loading",
    "apiKeyLinkTooltip": "Link to the API key page",
    "downloadLinkTooltip": "Link to the download page",
    "getApiKey": "Get API Key",
    "free": "Free",
    "supportsOffline": "Supports Offline",
    "resetTheme": "Reset Theme"
  },
  "historySidebar": {
    "chatHistoryTitle": "Chat History",
    "nothingCurrently": "Nothing Currently",
    "today": "Today",
    "yesterday": "Yesterday",
    "last7Days": "Last 7 Days",
    "last1Month": "Last 1 Month",
    "earlier": "Earlier"
  },
  "voiceSettingsBar": {
    "voiceServicesConfig": "Voice Services Configuration",
    "textToVoiceService": "Text To Voice Service",
    "voiceToTextService": "Voice To Text Service",
    "clickToShowMoreInfo": "Click to show more information",
    "vscodeSpeechExtensionNotice": "Run on local CPU. It will open an temporary text file and close after input is done (Auto Closure after silence). Sorry for but this must be done to use the built-in voice service, if you have any better idea please let us know! This relies on the built-in voice to text service in VSCode. If you have not installed it, you can do so by <marketplace />.",
    "sox": "SoX",
    "alsa": "ALSA",
    "microphoneAccessNotice": "Notice: This will require microphone access with <sox /> installed on Windows/Mac or <alsa /> on Linux. This is required as we use shell for recording audio. (If you have a better way, please suggest on <github />)",
    "openAIVoiceConfig": "OpenAI Voice Configuration",
    "openAIVoiceLabel": "(OpenAI)",
    "openAIPreviewVoices": "Preview voices at OpenAI website",
    "selectVoice": "Select a voice",
    "gptSoVitsVoiceConfig": "GPT-SoVits Voice Configuration",
    "gptSoVitsVoiceLabel": "(GPT-SoVits)",
    "gptSoVitsLearnMore": "Find out more about how to set up GPT-SoVits model locally",
    "selectReferenceVoice": "Select a reference voice",
    "gptSoVitsAdvanceSettings": "GPT-SoVits Advance Settings"
  },
  "gptSoVitsSettingsBar": {
    "title": "GPT-SoVits Settings",
    "clientHostLabel": "Client Host",
    "clientHostExample": "(e.g. http://127.0.0.1:9880/)",
    "clientHostNote": "Note: If you are using the old API V1, the default host is http://127.0.0.1:9880/, for V2, the default host is http://127.0.0.1:9880/tts/",
    "selectedReferenceVoiceLabel": "Selected Reference Voice",
    "selectReferenceVoicePlaceholder": "Select a reference voice",
    "referenceVoicesLabel": "Reference Voices",
    "addVoiceButton": "Add Voice",
    "note": "Note: Chinese also support English content above GPT-SoVITS-beta0706 version."
  },
  "gptSoVitsSettingsBarSortableItem": {
    "newVoice": "New Voice",
    "nameLabel": "Name",
    "referWavPathLabel": "Refer WAV Path",
    "referTextLabel": "Refer Text",
    "promptLanguageLabel": "Prompt Language",
    "englishLabel": "English",
    "chineseLabel": "Chinese",
    "japaneseLabel": "Japanese"
  },
  "codeCompletionSettingsBar": {
    "manualConfig": "Manually Trigger Configuration",
    "manualTriggerLabel": "Manual Trigger Code Completion",
    "showMoreInfoTooltip": "Click to show more information",
    "enableManualTrigger": "Enable Manual Trigger Code Completion",
    "manualModelServiceLabel": "Model Service for Manual Code Completion",
    "manualModelLabel": "Model for Manual Code Completion",
    "editKeybinding": "Edit Keybinding",
    "manualDescription": "This will use more context, resources and token to provide higher quality completions.",
    "autoConfig": "Auto Trigger Configuration",
    "autoTriggerLabel": "Auto Trigger Code Completion",
    "enableAutoTrigger": "Enable Auto Trigger Code Completion",
    "autoModelServiceLabel": "Model Service for Auto Code Completion",
    "ollamaTooltip": "Currently only support ollama",
    "autoModelLabel": "Model for Auto Code Completion",
    "autoModelTooltip": "We currently support the model which are in <supportModels /> fill hole model template. Please help us to add more model in GitHub if you interested.",
    "autoDescription": "This will use when you typing pause for a moment. Which mean will faster suit for simple code snippet."
  },
  "modelAdvanceSettingBar": {
    "descriptions": {
      "systemPrompt": "The system prompt for the model. This can be used to introduce context to the model, such as a description of the conversation so far. Or, you can make the model more professional or casual by changing the prompt.",
      "maxTokens": "The maximum number of tokens that can be generated in the chat completion. The total length of input tokens and generated tokens is limited by the model's context length. What is token? Tokens are words, character sets, or combinations of words and punctuation that are used by large language models (LLMs) to decompose text into.",
      "temperature": "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or `top_p` or `top_k` but not more than one.",
      "topP": "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. We generally recommend altering this or `temperature` or `top_k` but not more than one.",
      "topK": "An alternative to sampling with temperature, called top-k sampling, where the model considers the results of the top k most likely tokens. So 2 means that only the top 2 most likely tokens are considered. We generally recommend altering this or `temperature` or `top_p` but not more than one.",
      "presencePenalty": "Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.",
      "frequencyPenalty": "Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.",
      "stop": "A list of tokens where the model should stop generating further tokens. Separate each token with a new line for multiple tokens. If you want to stop the model from generating more tokens, you can add a stop token here."
    },
    "notes": {
      "topK": "Some models may not support top-k sampling."
    }
  },
  "modelAdvanceSettingFormItem": {
    "clickToShowMoreInfo": "Click to show more information",
    "enterSystemPrompt": "Enter system prompt",
    "enterStopSequence": "Enter stop sequence separated by new line",
    "clearField": "Clear field",
    "systemPrompt": "System Prompt",
    "maxTokens": "Max Tokens",
    "temperature": "Temperature",
    "topP": "Top P",
    "topK": "Top K",
    "presencePenalty": "Presence Penalty",
    "frequencyPenalty": "Frequency Penalty",
    "stop": "Stop Sequences"
  },
  "saveSystemPromptModal": {
    "title": "Save System Prompt",
    "promptNameRequired": "Please enter a name for the prompt",
    "contentRequired": "Please enter the prompt content"
  },
  "loadSystemPromptBar": {
    "title": "Load System Prompt",
    "confirmDelete": "Are you sure you want to delete this system prompt?"
  },
  "editPromptForm": {
    "title": "Edit Prompt",
    "promptNameRequired": "Please enter a name for the prompt",
    "contentRequired": "Please enter the prompt content"
  },
  "tags": {
    "enterOrSelectTag": "Enter or select tag",
    "addTag": "New Tag"
  },
  "modelForm": {
    "removeOutdatedModelsNotice": "Notice: This will also remove the outdated models from the list",
    "fetchOllamaModels": "Fetch available models from host server",
    "fetchLatestModels": "Fetch Latest Available Models"
  },
  "openRouterModelForm": {
    "browseAvailableModels": "Browse Available Models",
    "addModelManually": "Add Model Manually",
    "modelAlreadyInList": "Model {{name}} is already in your list."
  },
  "openRouterModelBrowserModal": {
    "browseModelsTitle": "Browse OpenRouter Models (Current Show: {{count}})",
    "searchModels": "Search models by name or ID",
    "free": "Free",
    "modality": "Modality",
    "instructType": "Instruct Type",
    "minContextLength": "Min Context Length",
    "notApplicable": "N/A",
    "maxTokens": "Max {{token}} tokens",
    "priceForPrompt": "The price for prompt",
    "priceForCompletion": "The price for completion",
    "perMillionTokens": "/M tokens"
  },
  "openRouterModelFormSortableItem": {
    "basicInformation": "Basic Information",
    "modelId": "Model ID",
    "modelIdTooltip": "The model ID will usually be in the format of <organization>/<model-name>",
    "modelIdPlaceholder": "e.g., openai/gpt-4o-mini",
    "nameTooltip": "What ever you want to call the model",
    "namePlaceholder": "Friendly name for the model",
    "contextLength": "Context Length",
    "contextLengthTooltip": "Maximum number of tokens",
    "contextLengthPlaceholder": "Maximum context length",
    "pricingInformation": "Pricing Information",
    "promptPrice": "Prompt Price",
    "promptPricePlaceholder": "Price per 1M tokens for prompts",
    "completionPrice": "Completion Price",
    "completionPricePlaceholder": "Price per 1M tokens for completions",
    "imagePrice": "Image Price",
    "imagePricePlaceholder": "Price for image processing",
    "providerInformation": "Provider Information",
    "providerContextLengthTooltip": "Maximum number of tokens the model can process",
    "isModerated": "Is Moderated",
    "isModeratedTooltip": "Whether the model has content moderation",
    "moderationStatus": "Moderation status",
    "notSpecified": "Not Specified",
    "newOpenRouterModel": "New OpenRouter Model"
  },
  "customModelFormSortableItem": {
    "apiUrl": "API URL",
    "apiMethod": "API Method",
    "textParameter": "Text Parameter",
    "imageParameter": "Image Parameter",
    "queryParameter": "Query Parameter",
    "includeQueryInHistory": "Include Query in History",
    "checkToAppendQueryToHistory": "Check to append user's latest query to history"
  },
  "imageContainer": {
    "imageNotFound": "Referenced image not found, might have been deleted."
  },
  "toolActionContainer": {
    "approve": "Approve",
    "reject": "Reject",
    "runCommand": "Run Command",
    "rejectByUserMessage": "I reject the {{toolName}} tool call request that you made. \n**Reason**: \n{{reason}}",
    "rejectionReasons": {
      "today": "Today is {{date}}",
      "incorrectParameters": "Some of your request parameters are incorrect",
      "selectWrongTool": "You selected the wrong tool, try another one",
      "unnecessaryToolUsage": "This tool is not necessary for the current task",
      "securityConcern": "The tool you selected may have security concerns or risks",
      "other": "Other reasons"
    }
  },
  "toolResponseContainer": {
    "feedbackFromUser": "Feedback from user",
    "continue": "Continue",
    "rollback": "Rollback",
    "fixIt": "Fix It",
    "retry": "Retry"
  },
  "inputMessageArea": {
    "pasteImagesOrMention": "Paste images or @mention"
  }
}
